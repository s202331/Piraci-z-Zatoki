---
title: "Analiza Sklepu Rowerowego"
author: "Jagoda Chęcińska, Piotr Łukowski, Tomasz Kotliński"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  markdown: 
    wrap: 72
---

# Piraci-z-Zatoki: Analiza Sklepu Rowerowego

## Wstęp

Klienci sklepu rowerowego wzięli udział w ankiecie, w której dostarczyli
szczegółowych informacji na swój temat, takie jak: status cywilny, płeć,
poziom dochodów, liczba dzieci, poziom wykształcenia, wykonywany zawód,
status posiadania domu, liczba samochodów, odległość do miejsca pracy,
region zamieszkania oraz wiek.

Celem analizy jest określenie, które z tych czynników mają największy
wpływ na decyzję o zakupie roweru.

------------------------------------------------------------------------

## Data Wrangling

```{r}
# Instalacja i załadowanie wszystkich wymaganych pakietów
install.packages(c("readr", "naniar", "dplyr","summarytools", "tidyr","car","psych", 
                   "ggplot2", "mice", "rpart","ggcorrplot","rpart.plot", "gridExtra", 
                   "factoextra", "plyr"))
library(readr)
library(naniar)
library(plyr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(mice)
library(rpart)
library(ggcorrplot)
library(rpart.plot)
library(factoextra)
library(gridExtra)
library(car)
library(psych)
library(summarytools)
read.csv("sklep_rowerowy.csv")
sklep_rowerowy <- read.csv("sklep_rowerowy.csv")
```

# Podstawowa analiza braków

## Identyfikacja braków w danych

```{r}
n_miss(sklep_rowerowy) # Sprawdzamy ilość NA w pliku
vis_miss(sklep_rowerowy) # Wizualizacja NA
miss_var_summary(sklep_rowerowy) # Podsumowanie braków w kolumnach
```

## Wizualizacja braków danych

```{r}
library(dplyr)  

### Obliczenie procentu braków w kolumnach
braki_procent <- sklep_rowerowy %>%
  summarise(across(everything(), ~ mean(is.na(.)) * 100)) %>%  # Obliczenie procentu braków
  pivot_longer(everything(), names_to = "Kolumna", values_to = "Procent")  # Przekształcenie do długiego formatu

### Wizualizacja braków
ggplot(braki_procent, aes(x = reorder(Kolumna, -Procent), y = Procent)) +  #Wizualizacja braków 
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(title = "Procent brakujących danych w kolumnach",
       x = "Kolumna", y = "% braków") +
  theme_minimal()
```

# Przetwarzanie braków
W tej sekcji dokonujemy przetwarzania braków danych poprzez:
1. **Zamianę pustych wartości na wartości brakujące (`NA`)** w kolumnach `Marital.Status`, `Gender` i `Home.Owner`.
2. **Konwersję wybranych kolumn na typ `factor`**, co umożliwia ich poprawne traktowanie jako zmiennych kategorycznych.
```{r}

sklep_rowerowy <- sklep_rowerowy %>%
  mutate(
    `Marital.Status` = na_if(`Marital.Status`, ""),
    Gender = na_if(Gender, ""),
    `Home.Owner` = na_if(`Home.Owner`, ""),
    `Marital.Status` = factor(`Marital.Status`),
    Gender = factor(Gender),
    Education = factor(Education),
    Occupation = factor(Occupation),
    `Home.Owner` = factor(`Home.Owner`),
    `Commute.Distance` = factor(`Commute.Distance`),
    Region = factor(Region),
    `Purchased.Bike` = factor(`Purchased.Bike`)
  )
```

# Imputacja Danych
W tej sekcji przeprowadzamy imputację brakujących wartości w zbiorze danych.
1. **Imputacja zmiennych liczbowych**: 
   - Brakujące wartości liczbowe zostają zastąpione średnią adaptacyjną (średnia obcięta o 10%).
2. **Imputacja zmiennych kategorycznych**: 
   - Wykorzystujemy metodę `Predictive Mean Matching (pmm)` z pakietu `mice`.

```{r}
### Imputacja Zmiennych liczbowych - średnia adaptacyjna
sklep_rowerowy <- sklep_rowerowy %>%
mutate(across(where(is.numeric), ~ ifelse(is.na(.), mean(., na.rm = TRUE, trim = 0.1), .)))

### Imputacja Zmiennych kategorycznych - metodą `pmm`

imputed_data <- mice(sklep_rowerowy, m = 5, method = 'pmm', seed = 123)
sklep_rowerowy <- complete(imputed_data)

sklep_rowerowy

n_miss(sklep_rowerowy)

## Wizualizacja braków danych po imputacji
vis_miss(sklep_rowerowy) + labs(title = "Braki danych po imputacji")

## Wizualizacja zmiennych liczbowych
sklep_rowerowy %>%
select(where(is.numeric)) %>%
pivot_longer(everything()) %>%
ggplot(aes(x = value)) +
geom_histogram(bins = 30, fill = "skyblue", color = "black") +
facet_wrap(~ name, scales = "free") +
labs(title = "Rozkład zmiennych liczbowych", x = "Wartość", y = "Częstość") +
theme_minimal()   

## Wizualizacja zmiennych kategorycznych
sklep_rowerowy %>%
select(where(is.factor)) %>%
pivot_longer(everything()) %>%
ggplot(aes(x = value)) +
geom_bar(fill = "steelblue") +
facet_wrap(~ name, scales = "free") +
labs(title = "Rozkład zmiennych kategorycznych", x = "Kategorie", y = "Liczba obserwacji") +
theme_minimal()  
```
Rozkład zmiennych kategorycznych:
- rozkład płci jest dość równomierny między kobietami a mężczyznami
- większość respondentów jest właścicielami domów
- większosć osób nie zakupiła roweru
- najwięcej badanych pokonuje krótki dystans do pracy 0-1 mili
------------------------------------------------------------------------

## Analiza Rozkładu Zmiennych Liczbowych

Na wykresach przedstawiono rozkład zmiennych liczbowych w zbiorze
danych:

-   **Age**: Zmienna Age wykazuje rozkład prawoskośny, z największą
    liczbą obserwacji w przedziale 20-40 lat.
-   **Cars**: Zmienna Cars przyjmuje wartości dyskretne, co wskazuje na
    ograniczoną liczbę unikalnych kategorii.
-   **Children**: Podobnie jak zmienna Cars, zmienna Children przyjmuje
    wartości dyskretne, również wskazując na ograniczoną liczbę
    unikalnych kategorii.
-   **Income**: Zmienna Income ma szeroki zakres wartości, z dużą
    koncentracją obserwacji w niższych przedziałach dochodów.Oznacza to,
    że większość osób w badanej grupie ma niższe dochody, podczas gdy
    mniejsza liczba osób zarabia znacznie więcej.

------------------------------------------------------------------------

## Wizualizacje
W tej sekcji przedstawiamy różne wykresy wizualizujące dane:
```{r}
# Wykres zakupu rowerów względem regionu
  ggplot(sklep_rowerowy, aes(x = Region, fill = Purchased.Bike)) +
    geom_bar(position = "dodge") +
    labs(title = "Zakup rowerów względem regionu",
         x = "Region",
         y = "Liczba zakupów",
         fill = "Zakup roweru (No = 0, Yes = 1)") +
    theme_minimal()
# Wykres zakupu rowerów względem przejechanych kilometrów
ggplot(sklep_rowerowy, aes(x = Commute.Distance, fill = Purchased.Bike)) +
  geom_bar(position = "dodge") +
  labs(title = "Zakup rowerów względem przejechanych kilometrów",
       x = "Dystans dojazdu do pracy",
       y = "Liczba zakupów",
       fill = "Zakup roweru (No = 0, Yes = 1)") +
  theme_minimal()

# Wykres zakupu rowerów względem dochodu
ggplot(sklep_rowerowy, aes(x = Income, fill = Purchased.Bike)) +
  geom_histogram(position = "dodge", bins = 30, alpha = 0.7) +
  labs(title = "Dochód klientów względem zakupu roweru",
       x = "Dochód",
       y = "Liczba klientów",
       fill = "Zakup roweru (No = 0, Yes = 1)") +
  theme_minimal()

# Wykres pudełkowy pokazujący rozkład dochodów w różnych regionach
ggplot(sklep_rowerowy, aes(x = Region, y = Income, fill = Region)) +
  geom_boxplot() +
  labs(title = "Dochód klientów w różnych regionach",
       x = "Region",
       y = "Dochód") +
  theme_minimal()
## korelacje zmiennych liczbowych
cor_matrix <- cor(sklep_rowerowy %>% select(where(is.numeric)), use = "complete.obs")
ggcorrplot(cor_matrix, hc.order = TRUE, type = "lower", lab = TRUE)
```
Największa liczba zakupów rowerów występuje w przypadku osób pokonujących krótkie dystanse (0-1 mili) do pracy, co sugeruje, że im krótszy dystans do pracy, tym większa skłonność do zakupu roweru. # czy umiecie zrobic tak żeby 10+ miles było na końcu wykresu, nie w środku, bo kategorie na osi poziomej rosna nie tak jak powinny, ja cos probowałam ale nie wyszło mi to przestawianie

Z wykresu pudełkowego mozna odczytać, że klienci z regionu Pacyfiku mają
najwyższe dochody, z medianą wyższą niż w pozostałych regionach, oraz
dużą liczbą wartości odstających. W Ameryce Północnej dochody są nieco
niższe, ale nadal wyższe niż w Europie, gdzie zaobserowano najniższą
medianę dochodów i mniejsze zróżnicowanie wartości. Rozrzut dochodów
jest największy w regionie Pacyfiku, co wskazuje na dużą różnorodność w
poziomie zarobków klientów.

Najwyższą korelację (0.53) obserwujemy między zmiennymi **Children** i
**Income**, co sugeruje, że większa liczba dzieci może wiązać się z
wyższymi dochodami. Ta zależność może wynikać z faktu, że rodziny z
większą liczbą dzieci mogą potrzebować większych dochodów, aby zapewnić
odpowiednie warunki życia. Natomiast zmienna **ID** nie wykazuje
istotnej korelacji z żadną inną zmienną, co jest zgodne z oczekiwaniami,
ponieważ pełni ona funkcję identyfikatora i nie ma bezpośredniego
związku z innymi analizowanymi zmiennymi.

## Model drzewa decyzyjnego
W tej sekcji budujemy model drzewa decyzyjnego do przewidywania zakupu roweru na podstawie dostępnych danych
```{r}
set.seed(123)
train_index <- sample(seq_len(nrow(sklep_rowerowy)), size = 0.7 * nrow(sklep_rowerowy))
train_data <- sklep_rowerowy[train_index, ]
test_data <- sklep_rowerowy[-train_index, ]

# Budowa drzewa decyzyjnego 
tree_model <- rpart(`Purchased.Bike` ~ ., data = train_data, method = "class")
tree_model

# Wizualizacja drzewa decyzyjnego
rpart.plot(tree_model, type = 4, extra = 104, fallen.leaves = TRUE, 
           box.palette = "RdBu", shadow.col = "gray", nn = TRUE )
# Powiększona wizualizacja drzewa decyzyjnego            
rpart.plot(tree_model, 
           type = 4,              # Styl rozwiniętych gałęzi
           extra = 104,           # Klasy, procenty, liczebności
           fallen.leaves = TRUE,  # Liście wyrównane do dołu
           box.palette = "RdBu",  # Kolorowe pudełka
           shadow.col = "gray",   # Cień dla efektu 3D
           nn = TRUE,             # Numery węzłów
           cex = 1.1)             # Większa czcionka (domyślnie 1.0)
```

# Przewidywanie na zbiorze testowym
```{r}
### W tej sekcji wykorzystujemy model drzewa decyzyjnego do przewidywania wyników na zbiorze testowym oraz oceniamy jego skuteczność

### Przewidywanie wyników
## Model jest stosowany do przewidywania wartości zmiennej `Purchased.Bike` na podstawie danych testowych.
tree_predictions <- predict(tree_model, test_data, type = "class")

### Ocena jakości modelu
## Aby określić skuteczność modelu, tworzymy macierz pomyłek, która pozwala ocenić liczbę poprawnie i błędnie sklasyfikowanych przypadków.
conf_matrix <- table(Predicted = tree_predictions, Actual = test_data$`Purchased.Bike`)
conf_matrix

### Obliczanie dokładności modelu
## Dokładność modelu obliczamy jako stosunek poprawnych przewidywań do całkowitej liczby obserwacji w zbiorze testowym.
accuracy <- mean(tree_predictions == test_data$`Purchased.Bike`)
cat("Dokładność modelu drzewa decyzyjnego:", round(accuracy * 100, 2), "%\n")
```

Model drzewa decyzyjnego poprawnie przewidział **98 przypadków "No"** i
**77 przypadków "Yes"**, ale popełnił **71 błędów fałszywie
negatywnych** i **54 fałszywie pozytywne**. Jego dokładność wynosi
**58,33%**, co oznacza, że klasyfikuje poprawnie nieco ponad połowę
przypadków. Wynik wskazuje na umiarkowaną skuteczność, sugerując
potrzebę dalszej optymalizacji modelu. \# Segmentacja klientów
(Klasteryzacja K-średnich)

```{r}
### W tej sekcji przeprowadzamy segmentację klientów metodą klasteryzacji K-średnich. Klasteryzacja pozwala na grupowanie klientów o podobnych cechach, co może być użyteczne w strategiach marketingowych i personalizacji oferty.

###Przygotowanie danych do klasteryzacji: wybieramy tylko zmienne liczbowe i je standaryzujemy.
## Aby zapewnić poprawność analizy:
#- Wybieramy tylko zmienne liczbowe.
#- Standaryzujemy dane, aby wszystkie zmienne miały porównywalną skalę.
cluster_data <- sklep_rowerowy %>% select(where(is.numeric))
cluster_data_scaled <- scale(cluster_data)

### Wybór optymalnej liczby klastrów
## Używamy metody WSS (within-cluster sum of squares), aby określić optymalną liczbę klastrów. Punkt załamania na wykresie wskazuje najlepszą liczbę grup.
library(factoextra)
fviz_nbclust(cluster_data_scaled, kmeans, method = "wss")

# Przeprowadzamy klasteryzację metodą K-średnich z 3 klastrami.
set.seed(123)
kmeans_model <- kmeans(cluster_data_scaled, centers = 3, nstart = 25)

# Wizualizacja wyników klasteryzacji.
fviz_cluster(kmeans_model, data = cluster_data_scaled, geom = "point") +
  labs(title = "Segmentacja klientów - Klasteryzacja K-średnich")
```

# Test Kruskala-Wallisa dla dochodu a poziomu wykształcenia

```{r}
# Test sprawdza, czy istnieją istotne różnice w medianach dochodu między grupami edukacyjnymi. Pomaga to ocenić wpływ wykształcenia na dochód, co może mieć znaczenie w strategiach marketingowych.
kruskal_test_income_education <- kruskal.test(Income ~ Education, data = sklep_rowerowy)
print(kruskal_test_income_education)
```

Test Kruskala-Wallisa został przeprowadzony w celu zbadania różnic w
dochodach według poziomu wykształcenia. Wyniki testu wskazują na
statystykę chi-kwadrat wynoszącą 119.15 przy 4 stopniach swobody, co
sugeruje istotne różnice między grupami. P-value jest znacznie mniejsza
niż poziom istotności α = 0.05, co pozwala na odrzucenie hipotezy
zerowej. Istnieją statystycznie istotne różnice w medianach dochodów w
zależności od poziomu wykształcenia.

# Test jednorodności wariancji (Levene’a)

```{r}
# Test Levene’a sprawdza, czy dochody w różnych regionach i poziomach wykształcenia mają podobną wariancję. Jest to istotne w analizie segmentacji klientów i klasteryzacji.
library(car)
leveneTest(Income ~ Region, data = sklep_rowerowy)

leveneTest(Income ~ Education, data = sklep_rowerowy)
```

Test Levene’a (sprawdzenie jednorodność wariancji)

Test Levene’a wykazał istotne statystycznie różnice w wariancji dochodów
między grupami wykształcenia, co potwierdzają wartości F = 15,435; p =
2,503e-07 (dla 2 grup) oraz F = 2,5284; p = 0,03922 (dla 4 grup).
Otrzymane wyniki wskazują na naruszenie założenia homogeniczności
wariancji, co sugeruje, że rozkład dochodów nie jest jednorodny w
analizowanych grupach.

# Test Shapiro-Wilka dla każdej grupy poziomu wykształcenia

```{r}
# Test ocenia normalność rozkładu dochodów w grupach edukacyjnych. Pomaga określić, czy stosować testy parametryczne czy nieparametryczne.
by(sklep_rowerowy$Income, sklep_rowerowy$Education, shapiro.test)
```
Dla wszystkich pięciu poziomów wykształcenia wyniki testu Shapiro-Wilka wskazują na brak normalności rozkładów dochodów, ponieważ w każdym przypadku wartość p jest mniejsza niż 0.05.
Brak normalności danych w każdej z grup oznacza, że założenie o normalnym rozkładzie danych, wymagane w testach parametrycznych takich jak ANOVA, jest naruszone. W takim przypadku nie należy stosować testu ANOVA, ponieważ może to prowadzić do błędnych wniosków. Zamiast tego, do analizy użyto testu nieparametrycznego Kruskala-Wallisa, który nie wymaga założenia normalności rozkładu.
# Test ANOVA dla dochodów w zależności od poziomu wykształcenia \_ usunęłam test ANOVA, bo nie mamy spełnionego założenia o noemalności, dlatego zrobiłam inny test, tym razem nieparametryczny kruskala-willisa

# Przeprowadzamy test Kruskal-Wallisa dla dochodów w zależności od poziomu wykształcenia

```{r}
# Przeprowadzenie testu Kruskal-Wallisa
kruskal_income_education <- kruskal.test(Income ~ Education, data = sklep_rowerowy)

# Wyświetlenie wyników testu
print(kruskal_income_education)

```

<<<<<<< HEAD
# Powiązanie testów z analizą klientów
```{r}
# - Test Kruskala-Wallisa**: Ocena różnic dochodów między grupami edukacyjnymi.
# - Test Levene’a**: Sprawdzenie jednorodności wariancji, istotne dla segmentacji klientów.
# - Test Shapiro-Wilka**: Weryfikacja założeń statystycznych dla dalszej analizy.
```
=======
Test Kruskala-Wallisa to nieparametryczny test statystyczny, który jest
używany do porównania median w więcej niż dwóch grupach. Wartość
chi-kwadrat wynosi 119,15, co wskazuje na istotną różnicę między grupami
w analizowanej zmiennej - dochodach. Bardzo mała wartość p (\< 2.2e-16)
sugeruje, że różnice między grupami są statystycznie istotne. Na
podstawie tych wyników, hipoteza zerowa, mówiąca o braku różnic w
medianach dochodów, zostaje odrzucona, co oznacza, że dochody różnią się
w zależności od poziomu wykształcenia.
>>>>>>> cf7b3fab27c317260d8d33353ceac2d8352bb17b

# Statystyki opisowe dla zmiennych liczbowych

```{r}
# W analizowanym zbiorze danych kluczowe zmienne liczbowe obejmują m.in. **dochód klientów (Income)** oraz **dystans dojazdu do pracy (Commute.Distance)**. Obliczamy podstawowe statystyki, takie jak:
## - **Średnia arytmetyczna (mean)** – określa przeciętną wartość danej cechy,
## - **Mediana (median)** – wartość środkowa, mniej podatna na wartości odstające,
## - **Odchylenie standardowe (sd)** – określa zmienność w ramach danej zmiennej

sklep_rowerowy %>% summarise(across(where(is.numeric), list(
  mean = ~mean(.x, na.rm = TRUE),
  median = ~median(.x, na.rm = TRUE),
  sd = ~sd(.x, na.rm = TRUE)
)))
```

# Statystyki opisowe dla zmiennych kategorycznych
# Analizujemy również zmienne kategoryczne, takie jak **region zamieszkania (Region)**, **poziom wykształcenia (Education)** czy **czy klient kupił rower (Purchased.Bike)**. Dla tych zmiennych tworzymy tabelę liczebności, aby zidentyfikować dominujące grupy klientów.
```{r}.
sklep_rowerowy %>% summarise(across(where(is.factor), ~list(table(.))))
```

# Podsumowanie statystyk opisowych

```{r, results='asis'}
# Aby uzyskać pełny wgląd w dane, generujemy szczegółowy raport zawierający statystyki opisowe wszystkich zmiennych, który możemy zapisać w formacie HTML. Dzięki temu łatwo możemy analizować zmienność dochodów, dominujące grupy klientów oraz potencjalne braki w danych..
library(summarytools)
dfSummary(sklep_rowerowy) %>% print(method = "pander", file = "podsumowanie_statystykiopisowe.html")
```
a
# 
#asda 
# 

# #
#

# Test kruskala widzę że mamy w 2 miejscch w anova i w test kruskala to bedzie trzeba wybrac gdzie go wstawić

# 

# 

# 
